{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "def scroll_to_end(driver, pause_time=2):\n",
    "    # Get initial scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down to the bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load the page\n",
    "        time.sleep(pause_time)\n",
    "\n",
    "        # Calculate new scroll height after scrolling\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        # Check if the scroll height has changed\n",
    "        if new_height == last_height:\n",
    "            break  # If heights are the same, exit the loop\n",
    "\n",
    "        last_height = new_height\n",
    "\n",
    "\n",
    "def scrape_linkedin_jobs(job_title, location, max_retries=3):\n",
    "    # Set up Chrome options for headless mode\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_argument(\"--disable-infobars\")  # Disable the \"Chrome is being controlled by automated test software\" message\n",
    "    chrome_options.add_argument(\"--disable-extensions\")  # Disable Chrome extensions that may flag the session\n",
    "    chrome_options.add_argument(\"--no-sandbox\")  # Use this for running on systems without graphical environment (like cloud)\n",
    "\n",
    "    # Set up the driver (make sure chromedriver is in your PATH)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Navigate to LinkedIn jobs search page\n",
    "    linkedin_url = \"https://www.linkedin.com/jobs/search/\"\n",
    "    driver.get(linkedin_url)\n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME,'contextual-sign-in-modal__modal-dismiss-icon').click()\n",
    "    except:\n",
    "        print('Login dismiss not found')\n",
    "\n",
    "    # Input the job title\n",
    "    search_title_box = driver.find_element(By.XPATH, '//input[@aria-label=\"Search job titles or companies\"]')\n",
    "    search_title_box.send_keys(job_title)\n",
    "    \n",
    "    # Input the location\n",
    "    search_location_box = driver.find_element(By.XPATH, '//input[@aria-label=\"Location\"]')\n",
    "    search_location_box.clear()  # Clear the default location\n",
    "    search_location_box.send_keys(location)\n",
    "    \n",
    "    # Click the search button\n",
    "    search_button = driver.find_element(By.CSS_SELECTOR, '#jobs-search-panel > form > button > icon > svg')\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(1)  # Wait for search results to load\n",
    "\n",
    "    for i in range(8):\n",
    "        scroll_to_end(driver)\n",
    "\n",
    "    if  len(driver.find_elements(By.CLASS_NAME, 'infinite-scroller__show-more-button'))>0:\n",
    "        for i in range(10):\n",
    "            search_more = driver.find_element(By.CLASS_NAME, 'infinite-scroller__show-more-button')\n",
    "            search_more.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "    # Scrape the job listings\n",
    "    job_listings = []\n",
    "    job_elements = driver.find_elements(By.CLASS_NAME, 'jobs-search__results-list')\n",
    "    job_elements = job_elements[0].find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "    for job_element in job_elements:\n",
    "        try:\n",
    "            job_title = job_element.find_element(By.CLASS_NAME, 'base-search-card__info').text\n",
    "            company_name = job_element.find_element(By.CLASS_NAME, 'base-search-card__subtitle').text\n",
    "            location = job_element.find_element(By.CLASS_NAME, 'job-search-card__location').text\n",
    "            job_link = job_element.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            \n",
    "            description = None\n",
    "            for retry in range(max_retries):\n",
    "                try:\n",
    "                    link = job_element.find_element(By.CLASS_NAME, 'base-card__full-link')\n",
    "                    link.click()\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    description = driver.find_element(By.CLASS_NAME, 'show-more-less-html__markup').text\n",
    "                    break  # Exit retry loop if successful\n",
    "                except Exception as e:\n",
    "                    print(f\"Attempt {retry+1} failed to get description: {e}\")\n",
    "                    if retry == max_retries - 1:\n",
    "                        print(\"Max retries reached. Skipping this job.\")\n",
    "                    time.sleep(2)  # Optional: add delay before retry\n",
    "\n",
    "            if description is None:\n",
    "                description = '-'  # Use '-' if description could not be retrieved\n",
    "            \n",
    "            job_listings.append({\n",
    "                'Job Title': job_title,\n",
    "                'Company': company_name,\n",
    "                'Location': location,\n",
    "                'Link': job_link,\n",
    "                'Description': description\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error while scraping job: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    return job_listings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    job_title = \"Data Engineer\"\n",
    "    location = \"Montreal, Quebec, Canada\"\n",
    "    \n",
    "    jobs = scrape_linkedin_jobs(job_title, location)\n",
    "    \n",
    "    for i, job in enumerate(jobs, start=1):\n",
    "        print(f\"Job {i}:\")\n",
    "        print(f\"Title: {job['Job Title']}\")\n",
    "        print(f\"Company: {job['Company']}\")\n",
    "        print(f\"Location: {job['Location']}\")\n",
    "        print(f\"Link: {job['Link']}\")\n",
    "        print(f\"Description: {job['Description']}\")\n",
    "        print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jobs_df = pd.DataFrame(jobs)\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.to_csv('jobs2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key='XXXXX')  # Use your API key\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = ''\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to analyze a single job description with the CV using the new OpenAI API\n",
    "def get_job_analysis(cv_text, job_title, company, location, description):\n",
    "    try:\n",
    "        # Construct the prompt\n",
    "        prompt = f\"\"\"\n",
    "        I have the following CV:\n",
    "        {cv_text}\n",
    "        \n",
    "        Now analyze the following job description for the role of '{job_title}' at '{company}' located in '{location}'.\n",
    "        Please provide the following:\n",
    "        1. A match score based on my qualifications.\n",
    "        2. Key skills or qualifications I meet or don't meet.\n",
    "        3. Suggestions on how to improve my chances of getting the job.\n",
    "\n",
    "        Job Description:\n",
    "        {description}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call the OpenAI chat completion using the latest client syntax\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that analyzes job descriptions and compares them to CVs.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract the response text\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing job: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to analyze multiple jobs and return a DataFrame\n",
    "def analyze_jobs(jobs_df, cv_text):\n",
    "    analysis_results = []\n",
    "    \n",
    "    for index, job in jobs_df.iterrows():\n",
    "        job_title = job['Job Title']\n",
    "        company = job['Company']\n",
    "        location = job['Location']\n",
    "        description = job['Description']\n",
    "        \n",
    "        # Get analysis from the GPT model\n",
    "        analysis = get_job_analysis(cv_text, job_title, company, location, description)\n",
    "        \n",
    "        analysis_results.append({\n",
    "            'Job Title': job_title,\n",
    "            'Company': company,\n",
    "            'Location': location,\n",
    "            'Analysis': analysis\n",
    "        })\n",
    "        \n",
    "        # To avoid rate limits, add a delay between API calls\n",
    "        time.sleep(2)  # Adjust sleep time if necessary\n",
    "\n",
    "    return pd.DataFrame(analysis_results)\n",
    "\n",
    "# Main function to extract the CV and analyze job listings\n",
    "def main(cv_pdf_path, jobs_df):\n",
    "    # Step 1: Extract CV text from PDF\n",
    "    cv_text = extract_text_from_pdf(cv_pdf_path)\n",
    "\n",
    "    if cv_text:\n",
    "        # Step 2: Analyze the jobs with the extracted CV\n",
    "        job_analysis_df = analyze_jobs(jobs_df, cv_text)\n",
    "        return job_analysis_df\n",
    "    else:\n",
    "        print(\"Error: Unable to extract text from the provided CV PDF.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Path to the CV PDF file\n",
    "    cv_pdf_path = './CV_En_BABAK.pdf'\n",
    "\n",
    "    # Run the job analysis\n",
    "    job_analysis_df = main(cv_pdf_path, jobs_df)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    if job_analysis_df is not None:\n",
    "        print(job_analysis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_analysis_df.to_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "data = job_analysis_df\n",
    "\n",
    "# Function to extract the match score from the text in the \"Analysis\" column\n",
    "def extract_match_score(text):\n",
    "    # Check for match score, allowing for different phrases and formats\n",
    "    match = re.search(r'(match score|score of|Match Score|Score)[\\s\\S]*?:?\\s*(\\d{1,2})/?(\\d{1,2})?%?', text, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        score_value = match.group(2)\n",
    "        max_value = match.group(3) if match.group(3) else \"100\"  # default to 100 if not percentage\n",
    "        return f\"{score_value}/{max_value}\"\n",
    "    \n",
    "    # Check for N/A or text-based responses\n",
    "    na_match = re.search(r'(N/A|No qualifications|Inapplicable)', text, re.IGNORECASE)\n",
    "    if na_match:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    # Return None if no score is found\n",
    "    return None\n",
    "\n",
    "# Apply the function to the \"Analysis\" column\n",
    "data['Match Score'] = data['Analysis'].apply(extract_match_score)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file = 'output_with_match_scores.csv'\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data[['Job Title', 'Match Score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by= 'Match Score',ascending=False).to_csv('analysis_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key='XXXXXXXX')  # Use your API key\n",
    "\n",
    "# Function to analyze a single job description with the CV using the new OpenAI API\n",
    "def cover_letter_writer(cv_text, job_title, company, location, analysis):\n",
    "    try:\n",
    "        # Construct the prompt\n",
    "        prompt = f\"\"\"\n",
    "        I have the following CV:\n",
    "        {cv_text}\n",
    "        \n",
    "        Now write a coverletter for the role of '{job_title}' at '{company}' located in '{location}'.\n",
    "        Please consider analysis, and company information. also cv information\n",
    "\n",
    "        analysis:\n",
    "        {analysis}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call the OpenAI chat completion using the latest client syntax\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are a professional, experienced '{job_title}' with a good ability of writing which can write coverletters with simple words and not similar to AI writings which can get the jobs\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract the response text\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing job: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "def coverletter_writer(job):\n",
    "    cv_text = extract_text_from_pdf(cv_pdf_path)\n",
    "    out = cover_letter_writer(cv_text,job['Job Title'],job['Company'],job['Location'],job['Analysis'])\n",
    "    display(Markdown(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### cover letter for best n matches ###########################################################\n",
    "\n",
    "n = 5\n",
    "goods = data.sort_values(by= 'Match Score',ascending=False).head(n)\n",
    "\n",
    "for i in range(n):\n",
    "    job = goods.iloc[i]\n",
    "    print(f\"\"\"\\n -----------------------cover letter for {job['Job Title'].split('\\n')[0]} -----------------------\\n\"\"\")\n",
    "    coverletter_writer(job)\n",
    "    print('---------------------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
